{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80db6326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Emre\\coding\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 44 document(s) and split into 129 chunks.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "\n",
    "# Define the path to the PDF file\n",
    "# Making sure the PDF file is in the same directory or provides the correct path\n",
    "file_path = \"your_document.pdf\" \n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"Error: The file '{file_path}' was not found.\")\n",
    "else:\n",
    "    # Load the document\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Split the document into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    \n",
    "    print(f\"Loaded {len(documents)} document(s) and split into {len(chunks)} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9029080b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emre\\AppData\\Local\\Temp\\ipykernel_27196\\3467279166.py:4: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings_model = OllamaEmbeddings(model=\"llama2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created and saved to './rag_db'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "embeddings_model = OllamaEmbeddings(model=\"llama2\")\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    chunks,\n",
    "    embeddings_model,\n",
    "    persist_directory=\"./rag_db\"\n",
    ")\n",
    "\n",
    "print(\"Vector store created and saved to './rag_db'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2349c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG chain initialized with Ollama.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emre\\AppData\\Local\\Temp\\ipykernel_27196\\1265980495.py:4: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"llama2\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = Ollama(model=\"llama2\")\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "print(\"RAG chain initialized with Ollama.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d66c7398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Answer ---\n",
      "I'm not able to provide an answer to the question \"how old is the Eiffel Tower\" as it is not mentioned in any of the provided context pieces. The context only provides information on AI, its impact on jobs and society, and various initiatives related to AI training and education. Therefore, I don't know the answer to this question.\n",
      "\n",
      "--- Sources ---\n",
      "Source: your_document.pdf\n",
      "Content: trends-report-2023)\n",
      "39  Microsoft Research Paper â€“ Sparks of Artificial General Intelligence (https://www.microsoft.com/en-\n",
      "us/research/publication/sparks-of-artificial-general-intelligence-early-expe...\n",
      "Source: your_document.pdf\n",
      "Content: without the physical actor present and potentially long after they have died. The full impact of AI on jobs of \n",
      "the future is yet to be determined, but it is possible that labour strikes will be exper...\n",
      "Source: your_document.pdf\n",
      "Content: INTRODUCTION TO AI\n",
      "World Travel & Tourism Council\n",
      "< Contents  | 43\n",
      "press/2023/over-50-believe-ai-will-future-proof-their-careers-only-13-have-been-offered-ai-training)\n",
      "31  GitLab Global Software Devel...\n",
      "Source: your_document.pdf\n",
      "Content: supercomputer beat chess grandmaster Gary Kasparov in 1997, with artificial intelligence algorithms developed \n",
      "by IBM engineers. A few years later, in 2011, the IBM Watson computer won the US gameshow...\n"
     ]
    }
   ],
   "source": [
    "query = \"how old is the eiffel tower\"\n",
    "\n",
    "# Use the RAG chain to get a response\n",
    "response = rag_chain.invoke({\"query\": query})\n",
    "\n",
    "# Print the generated answer and the source documents that were used\n",
    "print(\"\\n--- Answer ---\")\n",
    "print(response[\"result\"])\n",
    "\n",
    "print(\"\\n--- Sources ---\")\n",
    "for doc in response[\"source_documents\"]:\n",
    "    print(f\"Source: {doc.metadata.get('source', 'Unknown')}\")\n",
    "    print(f\"Content: {doc.page_content[:200]}...\") # Print a snippet of the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221a29b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
